{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch11_ex10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/joaoflf/handson-ml/blob/master/ch11_ex10.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "0vMzB81NaFDm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Restart VM"
      ]
    },
    {
      "metadata": {
        "id": "c91a9dtfaDqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-00vitowLPtO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports and fetch tensorboard plugin"
      ]
    },
    {
      "metadata": {
        "id": "uHa9OD5LK_kI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "f7980ed7-2c1e-462d-f9e2-4c86634bbeed"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mixuala/colab_utils.git\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import os\n",
        "import colab_utils.tboard\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from functools import partial\n",
        "from datetime import datetime\n",
        "from random import choice"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'colab_utils'...\n",
            "remote: Counting objects: 219, done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 219 (delta 16), reused 43 (delta 13), pack-reused 171\u001b[K\n",
            "Receiving objects: 100% (219/219), 60.62 KiB | 7.58 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KiLM97miLV5E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setup logs directory and tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "LbUv5uRKLVXw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3ff03b10-0485-4fff-bc5c-c06b742d7021"
      },
      "cell_type": "code",
      "source": [
        "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
        "ROOT = %pwd\n",
        "root_log_dir = os.path.join(ROOT, 'tf_logs')\n",
        "colab_utils.tboard.launch_tensorboard( bin_dir=ROOT, log_dir=root_log_dir )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calling wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip ...\n",
            "calling unzip ngrok-stable-linux-amd64.zip ...\n",
            "ngrok installed. path=/content/ngrok\n",
            "status: tensorboard=False, ngrok=False\n",
            "tensorboard url= http://193501ae.ngrok.io\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'http://193501ae.ngrok.io'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "ado-uqpBLsN8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build neural nets"
      ]
    },
    {
      "metadata": {
        "id": "Rlsv6UEGLkGE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "n_inputs = 28 * 28\n",
        "learning_rate = 0.01\n",
        "momentum = 0.95\n",
        "\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
        "\n",
        "def create_hidden_layers(name, input_layer, no_layers, layer_size=100, activation_function=tf.nn.elu, initilalizer=he_init):\n",
        "    for i in range(1, no_layers+1):\n",
        "      hidden = tf.layers.dense(input_layer, layer_size, name=name+\"/hidden\"+str(i), kernel_initializer=initilalizer, activation=activation_function)\n",
        "      input_layer = hidden\n",
        "    return input_layer\n",
        "  \n",
        "X_a = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X_a')\n",
        "X_b = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X_b')\n",
        "y = tf.placeholder(tf.int32, shape=(None, 1), name='y')\n",
        "\n",
        "dnn_a = create_hidden_layers('dnn_a', X_a, 5)\n",
        "dnn_b = create_hidden_layers('dnn_b', X_b, 5)\n",
        "\n",
        "concat_layer = tf.layers.dense(tf.concat([dnn_a, dnn_b], 1), 10, name='dnn_concat', kernel_initializer=he_init, activation=tf.nn.elu)\n",
        "logits = tf.layers.dense(concat_layer, 1, name='logits', kernel_initializer=he_init)\n",
        "y_prob = tf.nn.sigmoid(logits)\n",
        "y_pred = tf.cast(tf.greater_equal(logits, 0), tf.int32)\n",
        "\n",
        "with tf.name_scope('loss'):\n",
        "  y_as_float = tf.cast(y, tf.float32)\n",
        "  xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_as_float, logits=logits)\n",
        "  loss = tf.reduce_mean(xentropy, name='loss')\n",
        "\n",
        "with tf.name_scope('train'):\n",
        "  optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
        "  training_op = optimizer.minimize(loss)\n",
        "\n",
        "with tf.name_scope('eval'):\n",
        "  y_pred_correct = tf.equal(y_pred, y)\n",
        "  accuracy = tf.reduce_mean(tf.cast(y_pred_correct, tf.float32), name='accuracy')\n",
        "\n",
        "\n",
        "loss_summary = tf.summary.scalar('Loss', loss)\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MemdpjaC2DEg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Create function to generate batches of mnist image pairs"
      ]
    },
    {
      "metadata": {
        "id": "RdZ_l3h82Cxk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "694718f6-4064-4975-998b-b51830e84c5b"
      },
      "cell_type": "code",
      "source": [
        "mnist = input_data.read_data_sets('/tmp/data/')\n",
        "mnist_train_images = mnist.train.images\n",
        "mnist_train_labels = mnist.train.labels\n",
        "                                 \n",
        "def generate_pairs_batch(X, y, batch_size):\n",
        "  X_pair_1 = []\n",
        "  X_pair_2 = []\n",
        "  y_pair = []\n",
        "\n",
        "  \n",
        "  while len(X_pair_1) < batch_size // 2:\n",
        "    idx1, idx2 = np.random.randint(0, len(X)-1, 2)\n",
        "    if (idx1 != idx2 and y[idx1] == y[idx2]):\n",
        "      X_pair_1.append(X[idx1])\n",
        "      X_pair_2.append(X[idx2])\n",
        "      y_pair.append([0])\n",
        "      \n",
        "  while len(X_pair_1) < batch_size:\n",
        "    idx, idx2 = np.random.randint(0, len(X)-1, 2)\n",
        "    if (idx1 != idx2 and y[idx1] != y[idx2]):\n",
        "      X_pair_1.append(X[idx1])\n",
        "      X_pair_2.append(X[idx2])\n",
        "      y_pair.append([1])\n",
        "      \n",
        "  rnd_indices = np.random.permutation(batch_size)\n",
        "      \n",
        "  return np.array(X_pair_1)[rnd_indices], np.array(X_pair_2)[rnd_indices], np.array(y_pair)[rnd_indices]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qjp268Bk009I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train neural net"
      ]
    },
    {
      "metadata": {
        "id": "d_sOiFInXhag",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1059
        },
        "outputId": "d3948c98-6be2-45f7-fc7e-b444cf65704d"
      },
      "cell_type": "code",
      "source": [
        "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "logdir = \"{}/run-{}/\".format(root_log_dir, now)\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
        "\n",
        "batch_size = 500\n",
        "n_epochs = 50\n",
        "batch_step = 0\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  \n",
        "  for epoch in range(n_epochs):\n",
        "    for iteration in range(len(mnist_train_images) // batch_size):\n",
        "        X_batch_a, X_batch_b, y_batch = generate_pairs_batch(mnist_train_images, mnist_train_labels, batch_size)\n",
        "        sess.run(training_op, feed_dict={X_a: X_batch_a, X_b: X_batch_b, y: y_batch})\n",
        "        batch_step+=1\n",
        "    summary_str, acc_train, loss_str = sess.run([loss_summary, accuracy, loss], feed_dict={X_a: X_batch_a, X_b: X_batch_b, y: y_batch})\n",
        "    file_writer.add_summary(summary_str,batch_step)\n",
        "    print(epoch, \"Train accuracy:\", acc_train, 'Loss:', loss_str)\n",
        "    \n",
        "    if epoch % 5 == 0:\n",
        "      X_test_a, X_test_b, y_test = generate_pairs_batch(mnist.test.images, mnist.test.labels, len(mnist.test.images))\n",
        "      acc_test = accuracy.eval(feed_dict={X_a: X_test_a, X_b: X_test_b, y: y_test})\n",
        "      print(epoch, \"Test accuracy:\", acc_test)\n",
        "      \n",
        "    save_path = saver.save(sess, './digit_compare_model.ckpt')\n",
        "  file_writer.close()\n",
        "  sess.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.264 Loss: 0.70405805\n",
            "0 Test accuracy: 0.5003\n",
            "1 Train accuracy: 0.756 Loss: 0.6485502\n",
            "2 Train accuracy: 0.44 Loss: 0.69411844\n",
            "3 Train accuracy: 0.5 Loss: 0.69911695\n",
            "4 Train accuracy: 0.53 Loss: 0.68604296\n",
            "5 Train accuracy: 0.646 Loss: 0.6537176\n",
            "5 Test accuracy: 0.6272\n",
            "6 Train accuracy: 0.7 Loss: 0.55715245\n",
            "7 Train accuracy: 0.708 Loss: 0.56826293\n",
            "8 Train accuracy: 0.776 Loss: 0.48485264\n",
            "9 Train accuracy: 0.874 Loss: 0.33398923\n",
            "10 Train accuracy: 0.722 Loss: 0.5043106\n",
            "10 Test accuracy: 0.8544\n",
            "11 Train accuracy: 0.844 Loss: 0.4161686\n",
            "12 Train accuracy: 0.902 Loss: 0.3304333\n",
            "13 Train accuracy: 0.83 Loss: 0.45069027\n",
            "14 Train accuracy: 0.842 Loss: 0.36861688\n",
            "15 Train accuracy: 0.956 Loss: 0.1568733\n",
            "15 Test accuracy: 0.9503\n",
            "16 Train accuracy: 0.852 Loss: 0.30841693\n",
            "17 Train accuracy: 0.962 Loss: 0.16562739\n",
            "18 Train accuracy: 0.834 Loss: 0.37564662\n",
            "19 Train accuracy: 0.868 Loss: 0.2956013\n",
            "20 Train accuracy: 0.828 Loss: 0.36544743\n",
            "20 Test accuracy: 0.8858\n",
            "21 Train accuracy: 0.874 Loss: 0.27947897\n",
            "22 Train accuracy: 0.934 Loss: 0.17575757\n",
            "23 Train accuracy: 0.948 Loss: 0.16643411\n",
            "24 Train accuracy: 0.97 Loss: 0.12149387\n",
            "25 Train accuracy: 0.952 Loss: 0.14554209\n",
            "25 Test accuracy: 0.9136\n",
            "26 Train accuracy: 0.932 Loss: 0.15286556\n",
            "27 Train accuracy: 0.97 Loss: 0.09775409\n",
            "28 Train accuracy: 0.95 Loss: 0.13821055\n",
            "29 Train accuracy: 0.974 Loss: 0.1295893\n",
            "30 Train accuracy: 0.954 Loss: 0.15340762\n",
            "30 Test accuracy: 0.9638\n",
            "31 Train accuracy: 0.964 Loss: 0.1129324\n",
            "32 Train accuracy: 0.84 Loss: 0.30175465\n",
            "33 Train accuracy: 0.946 Loss: 0.13901068\n",
            "34 Train accuracy: 0.938 Loss: 0.18530081\n",
            "35 Train accuracy: 0.954 Loss: 0.104390584\n",
            "35 Test accuracy: 0.9659\n",
            "36 Train accuracy: 0.95 Loss: 0.13687949\n",
            "37 Train accuracy: 0.968 Loss: 0.08681692\n",
            "38 Train accuracy: 0.892 Loss: 0.22331443\n",
            "39 Train accuracy: 0.98 Loss: 0.06481615\n",
            "40 Train accuracy: 0.978 Loss: 0.07957364\n",
            "40 Test accuracy: 0.936\n",
            "41 Train accuracy: 0.96 Loss: 0.110913314\n",
            "42 Train accuracy: 0.982 Loss: 0.056080237\n",
            "43 Train accuracy: 0.98 Loss: 0.06475479\n",
            "44 Train accuracy: 0.978 Loss: 0.07495988\n",
            "45 Train accuracy: 0.98 Loss: 0.078739665\n",
            "45 Test accuracy: 0.8415\n",
            "46 Train accuracy: 0.95 Loss: 0.1367289\n",
            "47 Train accuracy: 0.976 Loss: 0.07787639\n",
            "48 Train accuracy: 0.976 Loss: 0.06487508\n",
            "49 Train accuracy: 0.986 Loss: 0.054394115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n6ommKnBUGoK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build digit prediction NN resuing the comparison NN"
      ]
    },
    {
      "metadata": {
        "id": "lQb7VQGGQsZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c5b6cf8f-e6ff-4a31-e42f-8ae02df05379"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
        "\n",
        "dnn_outputs = create_hidden_layers(\"dnn_a\", X, 5)\n",
        "frozen_outputs = tf.stop_gradient(dnn_outputs)\n",
        "\n",
        "logits = tf.layers.dense(dnn_outputs, 10, name='outputs', kernel_initializer=he_init)\n",
        "\n",
        "with tf.name_scope('loss'):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name='loss')\n",
        "    \n",
        "with tf.name_scope('train'):\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
        "    training_op = optimizer.minimize(loss, name=\"training_op\")\n",
        "    \n",
        "with tf.name_scope('eval'):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1, name='correct')\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='accuracy')\n",
        "    \n",
        "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "logdir = \"{}/run-{}/\".format(root_log_dir, now)\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
        "\n",
        "batch_size = 500\n",
        "n_epochs = 50\n",
        "batch_step = 0\n",
        "\n",
        "loss_summary = tf.summary.scalar('Loss', loss)\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"dnn_a\")\n",
        "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "X_train, y_train = mnist.validation.images, mnist.validation.labels\n",
        "print(X_train.shape)\n",
        "  \n",
        "with tf.Session() as sess:\n",
        "  init.run()\n",
        "  restore_saver.restore(sess, \"./digit_compare_model.ckpt\")\n",
        "  batch_step = 0\n",
        "  for epoch in range(n_epochs):\n",
        "      rnd_idx = np.random.permutation(len(X_train))\n",
        "      for rnd_indices in np.array_split(rnd_idx, len(X_train) // batch_size):\n",
        "          X_batch, y_batch = X_train[rnd_indices], y_train[rnd_indices]\n",
        "          sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "          batch_step+=1\n",
        "      summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "      file_writer.add_summary(summary_str,batch_step)\n",
        "      if epoch % 10 == 0:\n",
        "          acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
        "          print(epoch, \"Test accuracy:\", acc_test)\n",
        "\n",
        "  save_path = saver.save(sess, \"./my_mnist_model_final.ckpt\")\n",
        "      \n",
        "  file_writer.close()\n",
        "  sess.close()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 784)\n",
            "INFO:tensorflow:Restoring parameters from ./digit_compare_model.ckpt\n",
            "0 Test accuracy: 0.9307\n",
            "10 Test accuracy: 0.954\n",
            "20 Test accuracy: 0.9572\n",
            "30 Test accuracy: 0.9575\n",
            "40 Test accuracy: 0.9573\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}