{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch11_ex9.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/joaoflf/handson-ml/blob/master/ch11_ex9.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Z3OHDkpPBqdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f661925-5212-468b-f277-88e97ec4c4cc"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mixuala/colab_utils.git\n",
        "import os\n",
        "import colab_utils.tboard\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from functools import partial"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'colab_utils' already exists and is not an empty directory.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zdASL4eZBqeG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Implement early stopping"
      ]
    },
    {
      "metadata": {
        "id": "enW-mKSOBqeI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "3358689b-41d6-45ee-88eb-2904480b7f27"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "from datetime import datetime\n",
        "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
        "root_logdir = 'tf_logs'\n",
        "logdir = '{}/run-{}/'.format(root_logdir, now)\n",
        "ROOT = %pwd\n",
        "colab_utils.tboard.launch_tensorboard( bin_dir=ROOT, log_dir=logdir )\n",
        "\n",
        "\n",
        "n_inputs = 28 * 28\n",
        "n_hidden1 = 150\n",
        "n_hidden2 = 150\n",
        "n_hidden3 = 150\n",
        "n_hidden4 = 150\n",
        "n_hidden5 = 150\n",
        "n_outputs = 5\n",
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
        "y = tf.placeholder(tf.int64, shape=(None), name='y')\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
        "\n",
        "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
        "dropout = tf.placeholder_with_default(False, shape=(), name='dropout')\n",
        "batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=0.9)\n",
        "\n",
        "dropout_rate = 0.5\n",
        "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
        "\n",
        "with tf.name_scope('dnn'):\n",
        "    hidden1 = tf.layers.dense(X_drop, n_hidden1, name='hidden1', kernel_initializer=he_init)\n",
        "    bn1 = batch_norm_layer(hidden1)\n",
        "    bn1_act = tf.nn.elu(bn1)\n",
        "    bn1_drop = tf.layers.dropout(bn1_act, dropout_rate, training=dropout)\n",
        "    hidden2 = tf.layers.dense(bn1_drop, n_hidden2, name='hidden2', kernel_initializer= he_init)\n",
        "    bn2 = batch_norm_layer(hidden2)\n",
        "    bn2_act = tf.nn.elu(bn2)\n",
        "    bn2_drop = tf.layers.dropout(bn2_act, dropout_rate, training=dropout)\n",
        "    hidden3 = tf.layers.dense(bn2_drop, n_hidden3, name='hidden3', kernel_initializer= he_init)\n",
        "    bn3 = batch_norm_layer(hidden3)\n",
        "    bn3_act = tf.nn.elu(bn3)\n",
        "    bn3_drop = tf.layers.dropout(bn3_act, dropout_rate, training=dropout)\n",
        "    hidden4 = tf.layers.dense(bn3_drop, n_hidden4, name='hidden4', kernel_initializer= he_init)\n",
        "    bn4 = batch_norm_layer(hidden4)\n",
        "    bn4_act = tf.nn.elu(bn4)\n",
        "    bn4_drop = tf.layers.dropout(bn4_act, dropout_rate, training=dropout)\n",
        "    hidden5 = tf.layers.dense(bn4_drop, n_hidden5, name='hidden5', kernel_initializer= he_init)\n",
        "    bn5 = batch_norm_layer(hidden5)\n",
        "    bn5_act = tf.nn.elu(bn5)\n",
        "    bn5_drop = tf.layers.dropout(bn5_act, dropout_rate, training=dropout)\n",
        "    logist_before_bn = tf.layers.dense(bn5_drop, n_outputs, name='outputs', kernel_initializer=he_init)\n",
        "    logits = tf.layers.batch_normalization(logist_before_bn, training=training, momentum=0.9, name='logits')\n",
        "    \n",
        "with tf.name_scope('loss'):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name='loss')\n",
        "    \n",
        "with tf.name_scope('train'):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss, name=\"training_op\")\n",
        "    \n",
        "# Model evalutation\n",
        "with tf.name_scope('eval'):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1, name='correct') #check if the logit with highest value in array is the same as y\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name='accuracy')\n",
        "\n",
        "loss_summary = tf.summary.scalar('Loss', loss)\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('/tmp/data/')\n",
        "\n",
        "batch_size = 500\n",
        "n_epochs = 1000\n",
        "X_train, y_train = mnist.train.images[mnist.train.labels < 5], mnist.train.labels[mnist.train.labels < 5]\n",
        "X_test, y_test = mnist.test.images[mnist.test.labels < 5], mnist.test.labels[mnist.test.labels < 5]\n",
        "X_val, y_val = mnist.validation.images[mnist.validation.labels < 5], mnist.validation.labels[mnist.validation.labels < 5]\n",
        "steps_since_winner = 0\n",
        "step_limit = 10\n",
        "best_loss = np.infty\n",
        "\n",
        "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    batch_step = 0\n",
        "    for epoch in range(n_epochs):\n",
        "        idx = np.random.permutation(len(X_train))\n",
        "        for indices in np.array_split(idx, len(idx) // batch_size):\n",
        "            X_batch, y_batch = X_train[indices], y_train[indices]\n",
        "            sess.run([training_op, extra_update_ops], feed_dict={training: True, dropout: False, X: X_batch, y: y_batch})\n",
        "            batch_step+=1\n",
        "        # Log in tensorboard\n",
        "        summary_str = loss_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        file_writer.add_summary(summary_str,batch_step)\n",
        "        \n",
        "        loss_cv, acc_cv = sess.run([loss, accuracy], feed_dict={X: X_val, y: y_val})\n",
        "        if (best_loss > loss_cv):\n",
        "            best_loss = loss_cv\n",
        "            steps_since_winner = 0\n",
        "            print('Best loss found:  {:.6f}\\t accuracy:  {:.6f}'.format(loss_cv, acc_cv))\n",
        "            save_path = saver.save(sess, './data/best_model_0_4_bn.ckpt')\n",
        "        else:\n",
        "            if (steps_since_winner < step_limit):\n",
        "                steps_since_winner+=1\n",
        "            else:\n",
        "                print('Early stopping.')\n",
        "                break\n",
        "\n",
        "    file_writer.close()\n",
        "\n",
        "end = time.time()\n",
        "print(\"Total training time: {:.1f}s\".format(end - start))\n",
        "        "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ngrok installed\n",
            "status: tensorboard=True, ngrok=True\n",
            "tensorboard url= http://3eec106b.ngrok.io\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "Best loss found:  0.188237\t accuracy:  0.974199\n",
            "Best loss found:  0.098237\t accuracy:  0.979672\n",
            "Best loss found:  0.069003\t accuracy:  0.984754\n",
            "Best loss found:  0.053068\t accuracy:  0.989445\n",
            "Best loss found:  0.043713\t accuracy:  0.989836\n",
            "Best loss found:  0.039273\t accuracy:  0.990618\n",
            "Best loss found:  0.028934\t accuracy:  0.992181\n",
            "Best loss found:  0.027530\t accuracy:  0.991790\n",
            "Best loss found:  0.023650\t accuracy:  0.992963\n",
            "Best loss found:  0.018847\t accuracy:  0.995700\n",
            "Best loss found:  0.018096\t accuracy:  0.994136\n",
            "Best loss found:  0.016125\t accuracy:  0.994527\n",
            "Best loss found:  0.015750\t accuracy:  0.996091\n",
            "Best loss found:  0.014733\t accuracy:  0.996091\n",
            "Best loss found:  0.013334\t accuracy:  0.996873\n",
            "Best loss found:  0.012664\t accuracy:  0.996482\n",
            "Early stopping.\n",
            "Total training time: 52.9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i8EIt5HcBqeS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "546a5ecb-897f-47d9-bb20-074cbaeba861"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "\n",
        "    saver.restore(sess, './data/best_model_0_4_bn.ckpt')\n",
        "    acc_train = sess.run(accuracy, feed_dict={X: X_train, y: y_train})\n",
        "    acc_test = sess.run(accuracy, feed_dict={X: X_test, y: y_test})\n",
        "    print('Without Dropout: train accuracy: {:.2f}\\t test accuracy: {:.2f}'.format(acc_train * 100, acc_test * 100))\n",
        "    \n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./data/best_model_0_4_bn.ckpt\n",
            "Without Dropout: train accuracy: 99.96\t test accuracy: 99.63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gwlZPFcuBqea",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Transfer learning"
      ]
    },
    {
      "metadata": {
        "id": "jZkVCsJNBqec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "440c2455-7b05-4556-dcf3-fc6f2573ba0b"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "restore_saver = tf.train.import_meta_graph('./data/best_model_0_4_bn.ckpt.meta')\n",
        "\n",
        "# for op in tf.get_default_graph().get_operations():\n",
        "#     print(op.name)\n",
        "\n",
        "X = tf.get_default_graph().get_tensor_by_name('X:0')\n",
        "y = tf.get_default_graph().get_tensor_by_name('y:0')\n",
        "training = tf.get_default_graph().get_tensor_by_name('training:0')\n",
        "dropout = tf.get_default_graph().get_tensor_by_name('dropout:0')\n",
        "loss = tf.get_default_graph().get_tensor_by_name('loss/loss:0')\n",
        "accuracy = tf.get_default_graph().get_tensor_by_name('eval/accuracy:0')\n",
        "\n",
        "# freeze first 5 layers, by minimizing only the last layer variables (logits)\n",
        "train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='hidden5')\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_rate, name='RMSProp')\n",
        "training_op = optimizer.minimize(loss, var_list=train_vars, name=\"training_op\")\n",
        "\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('/tmp/data/')\n",
        "\n",
        "batch_size = 500\n",
        "n_epochs = 1000\n",
        "X_train2, y_train2 = mnist.train.images[mnist.train.labels >= 5], mnist.train.labels[mnist.train.labels >= 5]-5\n",
        "X_test2, y_test2 = mnist.test.images[mnist.test.labels >= 5], mnist.test.labels[mnist.test.labels >= 5]-5\n",
        "X_val2, y_val2 = mnist.validation.images[mnist.validation.labels >= 5], mnist.validation.labels[mnist.validation.labels >= 5]-5\n",
        "steps_since_winner = 0\n",
        "step_limit = 10\n",
        "best_loss = np.infty\n",
        "\n",
        "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        idx = np.random.permutation(len(X_train2))\n",
        "        for indices in np.array_split(idx, len(idx) // batch_size):\n",
        "            X_batch, y_batch = X_train2[indices], y_train2[indices]\n",
        "            sess.run([training_op, extra_update_ops], feed_dict={training: True, dropout: False, X: X_batch, y: y_batch})\n",
        "        loss_cv, acc_cv = sess.run([loss, accuracy], feed_dict={X: X_val2, y: y_val2})\n",
        "        if (best_loss > loss_cv):\n",
        "            best_loss = loss_cv\n",
        "            steps_since_winner = 0\n",
        "            print('Best loss found:  {:.6f}\\t accuracy:  {:.6f}'.format(loss_cv, acc_cv))\n",
        "            save_path = saver.save(sess, './data/best_model_5_9_bn.ckpt')\n",
        "        else:\n",
        "            if (steps_since_winner < step_limit):\n",
        "                steps_since_winner+=1\n",
        "            else:\n",
        "                print('Early stopping.')\n",
        "                break\n",
        "\n",
        "    file_writer.close()\n",
        "\n",
        "end = time.time()\n",
        "print(\"Total training time: {:.1f}s\".format(end - start))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "Best loss found:  0.917658\t accuracy:  0.711302\n",
            "Best loss found:  0.584950\t accuracy:  0.865684\n",
            "Best loss found:  0.509098\t accuracy:  0.881654\n",
            "Best loss found:  0.499879\t accuracy:  0.899263\n",
            "Best loss found:  0.466927\t accuracy:  0.904177\n",
            "Best loss found:  0.449320\t accuracy:  0.911548\n",
            "Best loss found:  0.428723\t accuracy:  0.914005\n",
            "Best loss found:  0.420993\t accuracy:  0.920557\n",
            "Best loss found:  0.411393\t accuracy:  0.921785\n",
            "Best loss found:  0.404247\t accuracy:  0.925471\n",
            "Best loss found:  0.382775\t accuracy:  0.929156\n",
            "Best loss found:  0.368496\t accuracy:  0.938575\n",
            "Best loss found:  0.365889\t accuracy:  0.933251\n",
            "Best loss found:  0.361836\t accuracy:  0.935708\n",
            "Best loss found:  0.361646\t accuracy:  0.933251\n",
            "Best loss found:  0.349121\t accuracy:  0.936937\n",
            "Best loss found:  0.346553\t accuracy:  0.930385\n",
            "Best loss found:  0.340732\t accuracy:  0.939803\n",
            "Best loss found:  0.336310\t accuracy:  0.936527\n",
            "Best loss found:  0.332941\t accuracy:  0.940213\n",
            "Best loss found:  0.328866\t accuracy:  0.938984\n",
            "Best loss found:  0.328763\t accuracy:  0.937756\n",
            "Best loss found:  0.325781\t accuracy:  0.941441\n",
            "Best loss found:  0.320026\t accuracy:  0.944308\n",
            "Best loss found:  0.315444\t accuracy:  0.945536\n",
            "Best loss found:  0.315060\t accuracy:  0.940622\n",
            "Best loss found:  0.310487\t accuracy:  0.946355\n",
            "Best loss found:  0.310244\t accuracy:  0.942260\n",
            "Early stopping.\n",
            "Total training time: 39.4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4QmOJKynBqel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3c0889f5-8eb2-49ab-ec5b-963724a20bd6"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "\n",
        "    saver.restore(sess, './data/best_model_5_9_bn.ckpt')\n",
        "    acc_train = sess.run(accuracy, feed_dict={X: X_train2, y: y_train2})\n",
        "    acc_test = sess.run(accuracy, feed_dict={X: X_test2, y: y_test2})\n",
        "    print('Without Dropout: train accuracy: {:.2f}\\t test accuracy: {:.2f}'.format(acc_train * 100, acc_test * 100))\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./data/best_model_5_9_bn.ckpt\n",
            "Without Dropout: train accuracy: 94.13\t test accuracy: 93.44\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}